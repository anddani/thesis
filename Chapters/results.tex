\textit{Results from the JNI tests, FFT libraries and NEON optimizations are presented here.}

%%==================================================================
%% JNI-Tests
%%==================================================================
\section{JNI}
The results from the tests that measure the JNI overhead can be found in Table~\ref{tab:jni:common}. These tests are presented with block sizes defined in chapter \ref{ch:method} - Method. Execution time and confidence intervals are given in microseconds and are rounded to four decimal points. The number before the $\pm$ sign is the sample mean and the number after $\pm$ is a two sided confidence interval with a confidence level of $95\%$. Each test was executed 100 times to ensure that we get reliable sample means.

The test labeled \textbf{No params} is the test where a native void function with no parameters that returns immediately was called. \textbf{Vector} takes a \texttt{jdoubleArray} and returns a \texttt{jdoubleArray} immediately. \textbf{Convert} takes a \texttt{jdoubleArray}, converts it to a native array using \texttt{GetPrimitiveArrayCritical()}, converts it back to a \texttt{jdoubleArray} using \texttt{ReleasePrimitiveArrayCritical()} and returns a \texttt{jdoubleArray}. \textbf{Columbia} takes three \texttt{jdoubleArray}s, converts them the same way and returns the same way.

No surprising data regarding the first two tests were found. Neither the \textbf{No params} nor \textbf{Vector} tests had a clear increase in execution time for an increase in block size. \textbf{Vector} did have a higher mean for block size \textbf{65536}. On the other hand, we can see that the 95\% confidence interval is very large ($\pm 3.1960$ \textmu s). This is likely due to its high standard deviation of 16.3058 found in Appendix \ref{appendix:results} Table \ref{tab:appendix:raw:jni:vector}. Likewise, there is a spike in execution time mean for a block size of \textbf{1024} in the \textbf{Convert} test.


% STILL RELEVANT??
% DISCUSS HERE WHEN CORRECT DATA IS GATHERED
% As seen in Table \ref{tab:jni:common}, the execution times for calling the JNI varied in the range of one microseconds and 14 microseconds. \textbf{Columbia} with block size \textbf{6}

\begin{table}[H]
    \centering
    \caption{Results from the JNI tests, Time (\textmu s)}
    \label{tab:jni:common}
    \input{Data/results/JNI/common_table_JNI.tex}
\end{table}



%%==================================================================
%% FFT-Tests
%%==================================================================
\section{FFT Libraries}
The results from the FFT Libraries are presented in line graphs, both language specific and graphs with both Java and C++ are given to illustrate the differences between languages and also provide differences for specific languages clearly. The time unit for these tests are presented in milliseconds. This was because the FFT ran in ranges below one millisecond and above one second among different algorithms and different block sizes. The means were calculated from the results of 100 test runs.  In each C++ line graph, the fastest Java test was added to make it easier to get a reference to compare the languages.

%=========%
%= SMALL =%
%=========%
\subsection{Small block sizes}
Results from the small blocks tests shows a clear difference between the different algorithms. In Figure~\ref{fig:all:line:small}, Princeton Recursive in Java perform the worst. Princeton Recursive in C++ and Princeton Iterative in Java perform better than Princeton Recursive Java although worse than the rest of the algorithms. The rest of the algorithms perform similarly and does not seem to grow given the small block sizes.

\begin{figure}
    \centering
    \input{Data/results/FFT/line_graph_SMALL.tex}
    \caption{Line graph for all algorithms, \emph{small} block sizes}
    \label{fig:all:line:small}
\end{figure}

As we can see in Figure~\ref{fig:java:line:small}, the standard deviation of Princeton Recursive and Princeton Iterative are very large. This means that the samples were sparse and as a result of this, not a reliable mean. We can see in Table~\ref{tab:java:small} that the confidence interval is generally larger for Princeton Iterative and Princeton Recursive compared to Columbia Iterative.

\begin{figure}
    \centering
    \input{Data/results/FFT/Java_line_graph_SMALL.tex}
    \caption{Java line graph for \emph{small} block sizes with standard deviation error bars}
    \label{fig:java:line:small}
\end{figure}

\begin{table}
    \centering
    \caption{Java results table for \emph{small} block sizes, Time (ms)}
    \label{tab:java:small}
    \input{Data/results/FFT/Java_common_table_SMALL.tex}
\end{table}

As for the C++ tests, the results were less scattered and had a more apparent increase in time with increasing block sizes. We can also see that the slowest algorithm, Princeton Recursive, has the largest standard deviation. It is clear by looking at Table~\ref{tab:cpp:small} that KISS performs the best, followed by Columbia Iterative, Princeton Iterative and then Princeton Recursive. If we look at the Java implementation, it has a general decrease in execution time for larger block sizes although it is faster than Princeton Iterative and Recursive.

\begin{figure}
    \centering
    \input{Data/results/FFT/CPP_line_graph_SMALL.tex}
    \caption{C++ line graph for \emph{small} block sizes with standard deviation error bars}
    \label{fig:cpp:line:small}
\end{figure}

\begin{table}
    \centering
    \caption{C++ results table for \emph{small} block sizes, Time (ms)}
    \label{tab:cpp:small}
    \resizebox{\columnwidth}{!}{
        \input{Data/results/FFT/CPP_common_table_SMALL.tex}
    }
\end{table}


%==========%
%= MEDIUM =%
%==========%
\subsection{Medium block sizes}
The medium block sizes continues the trend where Java Princeton Recursive performs the worst followed by Java Princeton Iterative and C++ Princeton Recursive. As for the small block sizes, Java Columbia Iterative, C++ Princeton Iterative, C++ Columbia Iterative and KISS have the smallest execution time and perform similarly.

\begin{figure}[H]
    \centering
    \input{Data/results/FFT/line_graph_MEDIUM.tex}
    \caption{Line graph for all algorithms, \emph{medium} block sizes}
    \label{fig:all:line:medium}
\end{figure}

The results found in Figure~\ref{fig:java:line:medium} are somewhat different than for the small block sizes. We can still see that Java Princeton Recursive diverges from the other algorithms. What is interesting is that it is now clearer which of Princeton Iterative and Columbia Iterative is the fastest. Columbia Iterative is clearly faster than Princeton Iterative as shown by the confidence intervals given in Table~\ref{tab:java:medium}. The standard deviations for the samples in the Princeton Recursive and Princeton Iterative are still relatively large compared to Columbia Iterative.

\begin{figure}
    \centering
    \input{Data/results/FFT/Java_line_graph_MEDIUM.tex}
    \caption{Java line graph for \emph{medium} block sizes with standard deviation error bars}
    \label{fig:java:line:medium}
\end{figure}
\begin{table}
    \centering
    \caption{Java results table for \emph{medium} block sizes, Time (ms)}
    \label{tab:java:medium}
    \input{Data/results/FFT/Java_common_table_MEDIUM.tex}
\end{table}

For the C++ algorithms, it is now clearer to see in which order the algorithms rank regarding performance in Figure~\ref{fig:cpp:line:medium}. Princeton Recursive perform the worst while the rest has similar execution times. It is now clear that KISS performs best, followed by Columbia Iterative and then Princeton Iterative. The Java Columbia Iterative implementation proves to be faster than Princeton for block sizes smaller than 4096.

In Table~\ref{tab:cpp:medium} we can see that the confidence intervals are relatively small, meaning these results have higher precision than for the same test with smaller block sizes. We can also see that there is no overlap between any confidence intervals thereby giving us a strong indication that the order in performance given in the previous paragraph is true.

\begin{figure}
    \centering
    \input{Data/results/FFT/CPP_line_graph_MEDIUM.tex}
    \caption{C++ line graph for \emph{medium} block sizes with standard deviation error bars}
    \label{fig:cpp:line:medium}
\end{figure}
\begin{table}
    \centering
    \caption{C++ results table for \emph{medium} block sizes, Time (ms)}
    \label{tab:cpp:medium}
    \resizebox{\columnwidth}{!}{
        \input{Data/results/FFT/CPP_common_table_MEDIUM.tex}
    }
\end{table}

%=========%
%= LARGE =%
%=========%
\subsection{Large block sizes}
Figure~\ref{fig:all:line:large} shows the growth in execution time for increasing block sizes of type \emph{large}. It continues the trend set by the tests with a block size of \emph{medium}. It is easy to see which algorithms that perform worse than the others. As previous tests shows, Java Princeton Recursive, Java Princeton Iterative and C++ Princeton Recursive are still the slowest.

\begin{figure}
    \centering
    \input{Data/results/FFT/line_graph_LARGE.tex}
    \caption{Line graph for all algorithms, \emph{large} block sizes}
    \label{fig:all:line:large}
\end{figure}

The results for the Java tests with \emph{large} block sizes are presented in Figure~\ref{fig:java:line:large}. The results from \emph{large} verifies the order in which the algorithms performs. The order in performance for Java is still Columbia Iterative, Princeton Iterative and Princeton Recursive (where Columbia Iterative is the fastest).

\begin{figure}
    \centering
    \input{Data/results/FFT/Java_line_graph_LARGE.tex}
    \caption{Java line graph for \emph{large} block sizes with standard deviation error bars}
    \label{fig:java:line:large}
\end{figure}
\begin{table}
    \centering
    \caption{Java results table for \emph{large} block sizes, Time (ms)}
    \label{tab:java:large}
    \input{Data/results/FFT/Java_common_table_LARGE.tex}
\end{table}

Results for tests with \emph{large} block sizes in C++ produced some interesting results. In Figure~\ref{fig:cpp:line:large} Princeton Recursive has a much larger standard deviation than the other algorithms. It is also the slowest (see Table~\ref{tab:cpp:large}). We can also see in the same table that all algorithms are faster in C++ than their equivalent in Java and that there are no overlapping confidence intervals for a given algorithm or block size. Another thing to note is that the Columbia Iterative algorithm performs almost the same between Java and C++. This is not the case for Princeton Iterative or Recursive.

\begin{figure}
    \centering
    \input{Data/results/FFT/CPP_line_graph_LARGE.tex}
    \caption{C++ line graph for \emph{large} block sizes with standard deviation error bars}
    \label{fig:cpp:line:large}
\end{figure}
\begin{table}
    \centering
    \caption{C++ results table for \emph{large} block sizes, Time (ms)}
    \label{tab:cpp:large}
    \resizebox{\columnwidth}{!}{
        \input{Data/results/FFT/CPP_common_table_LARGE.tex}
    }
\end{table}

%%==================================================================
%% NEON-Tests
%%==================================================================
\section{Optimizations}
The NEON optimizations proved to be very efficient for \emph{extra large} block sizes. These results can be found in Table~\ref{tab:neon:extra}. Comparing these figures with the results, for the same block sizes in Java (Table~\ref{tab:java:float:extra}), we can see that the results from the NEON tests are more than double the speed of the fastest Java implementation. Table~\ref{tab:java:float:extra} also shows that for very large block sizes, Princeton Iterative and Princeton Recursive are very inefficient compared to Columbia Iterative.

\begin{table}
    \centering
    \caption{NEON \texttt{float} results table for \emph{extra large} block sizes, Time (ms)}
    \label{tab:neon:extra}
    \input{Data/results/NEON/CPP_common_table_EXTRA.tex}
\end{table}

When comparing the NEON results from Table~\ref{tab:neon:extra} with the results from the C++ tests found in Table~\ref{tab:cpp:float:extra}, it is clear that vectorization as an optimization is beneficial. NEON intrinsics resulted in almost twice as fast execution time in comparison with the normal C++ tests. It was also much faster than Java, especially compared to Java Princeton Iterative/Recursive.

In Figure~\ref{fig:neon:line:extra} both the Iterative NEON and the Recursive NEON seems to have the same growth in execution time with increasing block size. Of these two algorithms, Iterative is the fastest. If we compare the results found for Java in Table~\ref{tab:java:float:extra} with the C++ results in Table~\ref{tab:cpp:float:extra} there is a big difference between the Princeton algorithms. The execution times are much larger in Java than in C++. The Java Columbia Iterative is faster than C++ Princeton Iterative for block sizes of 65536.

\begin{table}
    \centering
    \caption{Java \texttt{float} results table for \emph{extra large} block sizes, Time (ms)}
    \label{tab:java:float:extra}
    \input{Data/results/FLOAT/Java_common_table_EXTRA.tex}
\end{table}

\begin{table}
    \centering
    \caption{C++ \texttt{float} results table for \emph{extra large} block sizes, Time (ms)}
    \label{tab:cpp:float:extra}
    \resizebox{\columnwidth}{!}{
        \input{Data/results/FLOAT/CPP_common_table_EXTRA.tex}
    }
\end{table}

\begin{figure}
    \centering
    \input{Data/results/NEON/CPP_line_graph_EXTRA.tex}
    \caption{NEON results table for \emph{extra large} block sizes, Time (ms)}
    \label{fig:neon:line:extra}
\end{figure}


% \begin{figure}
%     \centering
%     \input{Data/results/FFT/line_graph_EXTRA.tex}
%     \caption{Line graph for all algorithms, \emph{extra large} block sizes}
%     \label{fig:all:line:extra}
% \end{figure}
