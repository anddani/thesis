\textit{Describing text}

\section{JNI Overhead}
The test results from the JNI tests showed that the overhead is small relative to the computation of the FFT algorithm. As long as it is being run once per calculation, it will not affect the performance significantly. If the JNI is called in a loop when it might not be necessary, the overhead add up and becomes a larger part of the total execution time. Another thing to note is that the execution time stay within about 10 \textmu s. They are also not growing with larger input.

The confidence intervals overlap for many of the values, meaning we cannot say whether or not one input yields a faster execution time than the other. Some larger block sizes has lower execution time than smaller block sizes and some grow for larger input. Because of this, it is reasonable to assume that nothing is done to the arrays when they are passed to the JNI, only pointers are copied. The \texttt{GetPrimitiveArrayCritical()} and \texttt{ReleasePrimitiveArrayCritical()} seem to introduce overhead when used on larger arrays. % <= CITE THIS ... as described in

\hilight{Discuss about the sudden spikes for means in JNI tests}

% The second tests compared the execution times for measuring the benefits of using a critical zone in native code. In Figure~\ref{}

\section{Floats and Doubles}
\hilight{Caching}

\hilight{Array would be twice as large if doubles were used.}\\
\hilight{Greater chance that the whole array can fit when using float elements.}
\hilight{There is a really big difference in both Java and C++.}

\section{Simplicity and Efficiency} % FFT-libraries

% Which is slowest and why (discussion)??
\hilight{Which is slowest and why??}

% Which is fastest and why (discussion)??
\hilight{Which is fastest and why??}

% Which tests triggered the GC??
\hilight{Which tests triggered the GC??}

% Precision (smaller intervals) for larger block sizes C++. Because larger execution times result in more consistent execution times??
\hilight{Precision (smaller intervals) for larger block sizes C++.}\\
\hilight{Because larger execution times result in more consistent execution times??}

\hilight{When choosing a java version, choose Columbia Iterative (Conclusion)}

One thing that is clear is that the Columbia Iterative algorithm is the best one to choose from of the Java versions. It performs better than both Princeton Iterative and Princeton Recursive. It also allows simple modifications such as changing between using \texttt{float}s or  \texttt{double}s to represent the data.

The reason Princeton Iterative and Princeton Recursive is slower in Java than in C++ is because they operate with \texttt{Complex} elements. Each time two \texttt{Complex} numbers are added, multiplied or subtracted, a new \texttt{Complex} object is created. This slows down the process and increases memory consumption, increasing work for the garbage collector.

% Although you can have two equally long implementations, one could be faster than the other.  It is important to do small tests with different sized data.

\hilight{Although you can have two equally long implementations,}
\hilight{one could be faster than the other.}\\
\hilight{It is important to do small tests with different sized data.}

% We can see in the tests that the best option is to choose KISS fft as it is the fastest of the options. BUT WHY??
\hilight{We can see in the tests that the best option is to choose KISS fft as it is the fastest of the options.}


% NEON iterative is faster than the recursive because...
\hilight{NEON iterative is faster than the recursive because...}

% For smaller Block sizes, the Java version is as fast as the C++ one. It is easier to implement and more flexible to edit. No need for complicated JNI integration.
\hilight{For smaller Block sizes, the Java version is almost as fast as the C++ one.}
\hilight{It is easier to implement and more flexible to edit. No need for complicated JNI integration.}

% It is with very large block sizes the difference is clear.
\hilight{It is with very large block sizes the difference is clear.}

% MAYBE THE C++ TESTS GOT MORE CLEAR GROWTH BECAUSE OF GETPRIMITIVEARRAY
\hilight{C++ Tests got more clear growth because of GetPrimitiveArrayCritical?}

\hilight{Speed required when rendering to screen at a constant refresh rate}

\section{Vectorization as Optimization}

\hilight{Implementation effort}

% Harder to maintain
\hilight{Harder to maintain}

% Pros/Cons

\hilight{Pros/Cons with NEON (Vectorization)}

As the results show, vectorization was an improvement in regards to efficiency. This was as expected because it is possible to process more elements for each instruction. 

% The benefit of fitting it all in cache.
\hilight{The benefit of fitting it all in cache.}

% With radix 4, it is possible to fit all in cache?

% Preparations for this such as lining up data correctly.
\hilight{Preparations by lining up data correctly.}\\
\hilight{Minimize RAM access.}

%%%
% When is the fastest required performance-wise??
\hilight{When is the fastest required performance-wise??}

% Limitations of the NEON intrinsics. Only works for ARM
\hilight{Limitations of the NEON intrinsics. Only works for ARM}

% Compare percentage speedup for iterative compared with recursive.
\hilight{Compare percentage speedup for iterative compared with recursive.}

% As we see, choosing the correct FFT implementation can have a large impact.

% Discuss differences in performance large java times, small java times WHY?
\hilight{Discuss differences in performance large java times, small java times WHY?}
