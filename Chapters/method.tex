\textit{To ensure that the experiments were carried out correctly, multiple tools for measurements were evaluated. Different implementations of the FFT were also compared to choose the ones that would typically be used in an Android project.}

\section{Experiment model}

% http://lessthanoptimal.github.io/Java-Matrix-Benchmark/manual/MethodologyRuntimeBenchmark/

In this thesis, different aspects that can affect execution time for an \gls{fft} implementation on Android were tested. A link to a repository including the benchmark program, data and algorithms can be found in Appendix~\ref{appendix:code}. To get an overview of how much impact they have, the following subjects were investigated:

\begin{enumerate}
    \item Cost of using the \gls{jni}
    \item Compare well known libraries
    \item Vectorization optimization with \gls{neon}, exclusive for native
    \item Using \texttt{float} and \texttt{double} as primary data types
\end{enumerate}

% The reason it is relevant to know how significant the \gls{jni} overhead is, is because we want to see for what data size the transition time for going between Java and native is irrelevant compared to the total execution time of the \gls{jni} call.
The first test investigates the overhead of calling the \gls{JNI}. This is so that we can find how large the proportion of a native call is actually going between Java and native code. This would also show how much repeated calls to native code would affect the performance of a program. By minimizing the number of calls to the \gls{jni}, a program would potentially become faster.

There are many different implementations of the \gls{fft} publicly available that could be of interest for use in a project. This test demonstrates how different libraries compare. It is helpful to see how viable different implementations are on Android, both for C++ libraries and for Java libraries. It can also be useful to know how small implementations can perform in terms of speed. The sample sizes used for the \gls{fft} can vary depending on the requirements for the implementation.

If the app needs to be efficient, it is common to lower the number of collected samples. This comes at a cost of accuracy. A fast \gls{fft} implementation allows for more data being passed to the \gls{fft}, improving frequency resolution. This is one of the reasons it is important to have a fast \gls{fft}.

Optimizations that are only possible in native code is a good demonstration of how a developer can improve performance even more and to perhaps achieve better execution times than what is possible in Java. Having one single source file is valuable, especially for native libraries. This facilitates the process of adding and editing libraries.

Finally, comparing how performance can change depending on which data types that are used is also interesting when choosing a given implementation. Using the \texttt{float} data type, you use less memory at the cost of precision. A \texttt{double} occupies double the amount of space compared to a \texttt{float}, although it allows higher precision numbers. Caching is one aspect that could be utilized by reducing the space required for the results array.

\subsection{Hardware}
The setup used for performing the experiments is described in Table~\ref{tab:hardware}.

\ifrelease
\begin{table}[H]
    \centering
    \caption{Hardware used in the experiments}
    \label{tab:hardware}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{Phone model} & Google Nexus 6P\\
        \hline
        \textbf{CPU model} & Qualcomm MSM8994 Snapdragon 810\\
        \hline
        \textbf{Core frequency} & 4x2.0 GHz and 4x1.55 GHz\\
        \hline
        \textbf{Total RAM} & 3 GB\\
        \hline
        \textbf{Available RAM} & 1.5 GB\\
        \hline
    \end{tabular}
\end{table}
\fi


\subsection{Benchmark Environment}
During the tests, both cellular and Wi-Fi were switched off. There were no applications running in the background while performing the tests during the experiments. Additionally, there were no foreground services running. This was to prevent any external influences from affecting the results. The software versions, compiler versions and compiler flags are presented in Table~\ref{tab:software}. The \texttt{-O3} optimization was used because it resulted in a small performance improvements compared to no optimization. The app was signed and packaged with release as build type. It was then transferred and installed on the device.

\ifrelease
\begin{table}[H]
    \centering
    \caption{Software used in the experiments}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{Android version} & 7.1.1\\
        \hline
        \textbf{Kernel version} & 3.10.73g7196b0d\\
        \hline
        \textbf{Clang/LLVM version} & 3.8.256229\\
        \hline
        \textbf{Java version} & 1.8.0\_76\\
        \hline
        \textbf{Java compiler flags} & \texttt{FLAGS HERE}\\
        \hline
        \textbf{C++ compiler flags} & \texttt{-Wall -std=c++14 -llog -lm -O3}\\
        \hline
    \end{tabular}
    \label{tab:software}
\end{table}
\fi

\subsection{Time measurement}
There are multiple methods of measuring time in Java. It is possible to measure the wall-clock time using the \texttt{System.currentTimeMillis()} method. There are drawbacks of using wall-clock time for measuring time. Because it is possible to manipulate the wall-clock at any time, it could result in too small or too large times depending on seemingly random factors. A more preferable method is to measure elapsed CPU time. This does not depend on a changeable wall-clock but rather it uses hardware to measure time. It is possible to use both \texttt{System.nanoTime()} and \texttt{SystemClock.elapsedRealtimeNanos()} for this purpose and the latter was used for the tests covered in this thesis.

The tests are executed with data formatted according to how they receive input. The output were also allowed to be formatted according to the output of the algorithm. No conversions were included in the timing of the algorithms Different algorithms accepts different data types as input parameters. When using an algorithm, the easiest solution would be to design your application around the algorithm (its input parameters and its return type). When possible to calculate external dependencies such as lookup tables, this is done outside the timer as it is only done once and not for each call to the \gls{fft}.

Some algorithms require a \texttt{Complex[]}, some require a \texttt{double[]} where the first half contains the real numbers and the second half contain the imaginary numbers, some require two double arrays, one for the real numbers and one for imaginary. Because of these different requirements, the timer encapsulates a function shown in Figure~\ref{fig:timer:pos}. The timer would not measure the conversion from the shared input to the input type required by the particular algorithm because you would normally already have the data in the same format as the algorithm require.

\ifrelease
\begin{figure}
\begin{lstlisting}[
        language={C++},
        basicstyle=\ttfamily\footnotesize,
        keywordstyle=\color{blue}\ttfamily,
        stringstyle=\color{red}\ttfamily,
        commentstyle=\color{green!70!black}\ttfamily,
    ]
    // Prepare formatted input
    double[] z = combineComplex(re, im);

    // Start timer
    long start = SystemClock.elapsedRealtimeNanos();

    // Native call
    double[] nativeResult = fft_princeton_recursive(z);

    // Stop timer
    long stop = SystemClock.elapsedRealtimeNanos() - start;
\end{lstlisting}
\caption{Timer placements for tests}
\label{fig:timer:pos}
\end{figure}
\fi

\subsection{Memory measurement}
The profiling tool provided by Android Studio was used to determine when a garbage collect is executed as well as how long the pause was. The method used to measure the memory was to attach the debugger to the app, execute a test and save the garbage collector logging. To measure each test on equal terms, the app was relaunched between tests. A table was created that contained the block size at which the garbage collector was first triggered. Another table containing the sum of the pauses caused by the garbage collector for each test was also created.

\section{Evaluation}
The unit of the resulting data was chosen to be in microseconds and milliseconds. Microseconds was used for the JNI tests while milliseconds was used for the library and optimization tests. To be able to have 100 executions run in reasonable time, the maximum size of the input data was limited to $2^{18} = 262144$ elements for all the tests. We need this many executions of the same test to get statistically significant results. The sampling rate is what determines the highest frequency that could be found in the result. The frequency range perceivable by the human ear ($\sim$ 20-22,000 Hz) is covered by the tests. According to the Nyquist theorem, the sampling rate must be at least twice the upper limit (44,000). Because the \gls{fft} is limited to sample sizes of powers of 2, the next power of 2 for a sampling rate of 44,000 is $2^{16}$. This size was chosen as the upper limit for the library comparisons.

For the SIMD tests, even larger sizes were used. This was to demonstrate how the execution time grew when comparing Java with low level optimizations in C++. Here, sizes up to $2^{18}$ were used because the steps from $2^{16} - 2^{18}$ illustrated this point clearly. It is also with these sizes the garbage collection is invoked many times due to large allocations.

\subsection{Data representation}
The block sizes chosen in the \gls{jni} and libraries tests are limited to every power of two from $2^4$ to $2^{16}$. For NEON tests, $2^{16} - 2^{18}$ will be used for the tests. The largest block size was chosen to be 44100 Hz because it is a very common sample frequency in spectral analysis. To get a resolution of at least one Hz for a frequency span of 0-22050 Hz, an \gls{fft} size of $2^{16}$ (next power of two for 44,100) is required. To be able to analyze an increase in execution time for larger data sizes, multiple data sizes had to be tested. The smallest sample size in these tests was $2^4$.

Every test result was not presented in Chapter~\ref{ch:results} - Results. In this chapter, only the results that were relevant to discuss are included. The tests results not found in the Results chapter is found in Appendix~\ref{appendix:results}. To visualize a result, tables and line graphs were used. \gls{fft} sizes were split into groups labeled \emph{small} size ($2^{4} - 2^{7}$), \emph{medium} size ($2^{8} - 2^{12}$), \emph{large} size ($2^{13} - 2^{16}$) and \emph{extra large} size ($2^{17} - 2^{18}$). This decision was made to allow the discussion to be divided into groups to see where the difference in performance between the algorithms is significant. An accelerometer samples at low frequencies, commonly at the ones grouped as \emph{small}.

For the normal \gls{fft} tests, the data type \texttt{double} was used and when presenting the results for the optimization tests, \texttt{float} was used. This was to ensure that we could discuss the differences in efficiency for choosing a specific data type.

\subsection{Sources of error}
% https://www2.southeastern.edu/Academics/Faculty/rallain/plab193/labinfo/Error_Analysis/06_Sources_of_Error.html
There are multiple factors that can skew the results when running the tests. Some are controllable and some are not. In these tests, allocation of objects was minimized as much as possible to prevent the overhead of allocating dynamic memory. Because the Java garbage collector is uncontrollable during runtime, this will depend on the sizes of the objects and other aspects dependent on a specific implementation such as the frequency of allocations. \gls{jni} allows native code to be run without interruption by the garbage collector by using the \texttt{GetPrimitiveArrayCritical} function call. Additionally, implementation details of the Java libraries were not altered to ensure that the exact library found was used.

% CPU throttling is another factor that can influence the execution times. This is a feature where the CPU changes its clock frequency to reduce heat generated by being in full load for too long. Different phones have different cooling capability and a profiler can provide information if this occurs during a test. 

\subsection{Statistical significance}
Because the execution times differ between runs, it is important to calculate the sample mean and a confidence interval. This way we have an expected value to use in our results as well as being able to say with a chosen certainty that one mean is larger than the other. To get an accurate sample mean, we must have a large sample size. The sample size chosen for the tests in this thesis was 100. The following formula calculates the sample mean \cite[p.263]{olofsson2012probability}:

\begin{equation*}
    \bar{X} = \frac{1}{N} \sum\limits_{k = 1}^{N} X_k
\end{equation*}

Now, the standard deviation is needed to find the dispersion of the data for each test. The standard deviation for a set of random samples $X_1, \dots, X_N$ is calculated using the following formula \cite[p.~302]{olofsson2012probability}:
\begin{equation*}
    s = \sqrt{\frac{1}{N - 1} \sum\limits_{k = 1}^{N}\left(X_k - \bar{X}\right)^2}
\end{equation*}

When comparing results, we need to find a confidence interval for a given test and choose a confidence level. For the data gathered in this study, a 95\% two-sided confidence level was chosen when comparing the data. To find the confidence interval we must first find the standard error of the mean using the following formula \cite[p.~304]{olofsson2012probability}:
\begin{equation*}
    SE_{\bar{X}} = \frac{s}{\sqrt{N}}
\end{equation*}

To find the confidence interval, we must calculate the margin of error by taking the appropriate $z^*$-value for a confidence level and multiplying it with the standard error. For a confidence level of 95\%, we get a margin of error as follows:

\begin{equation*}
    ME_{\bar{X}} = SE_{\bar{X}} \cdot 1.96
\end{equation*}

Our confidence interval will then be:
\begin{equation*}
    \bar{X} \pm ME_{\bar{X}}
\end{equation*}

\section{JNI Tests}
For testing the \gls{jni} overhead, four different tests were constructed. The first test had no parameters, returned void and did no calculations. The purpose of this test was to see how long it would take to call the smallest function possible. The function shown in Figure~\ref{fig:jni:empty} was used to test this.

\begin{figure}[H]
\begin{lstlisting}[
        language={C++},
        basicstyle=\ttfamily\footnotesize,
        keywordstyle=\color{blue}\ttfamily,
        stringstyle=\color{red}\ttfamily,
        commentstyle=\color{green!70!black}\ttfamily,
    ]
                 void jniEmpty(JNIEnv*, jobject) {
                     return;
                 }
\end{lstlisting}
\caption{JNI test function with no parameters and no return value}
\label{fig:jni:empty}
\end{figure}

For the second test, a function was written (see Figure~\ref{fig:jni:params}) that took a jdoubleArray as input and returned the same data type. The reason this test was made was to see if \gls{jni} introduced some extra overhead for passing an argument and having a return value.

\begin{figure}[H]
\begin{lstlisting}[
        language={C++},
        basicstyle=\ttfamily\footnotesize,
        keywordstyle=\color{blue}\ttfamily,
        stringstyle=\color{red}\ttfamily,
        commentstyle=\color{green!70!black}\ttfamily,
    ]
     jdoubleArray jniParams(JNIEnv*, jobject, jdoubleArray arr) {
         return arr;
     }
\end{lstlisting}
\caption{JNI test function with a double array as input parameter and return value}
\label{fig:jni:params}
\end{figure}

In the third test seen in Figure~\ref{fig:jni:conversion}, the \texttt{GetPrimitiveArrayCritical} function was called to be able to access the elements stored in \texttt{arr}. When all the calculations were done, the function would return \texttt{arr}. To overwrite the changes made on \texttt{elements}, a function called \texttt{ReleasePrimitiveArrayCritical} had to be called.

\begin{figure}[H]
\begin{lstlisting}[
        language={C++},
        basicstyle=\ttfamily\footnotesize,
        keywordstyle=\color{blue}\ttfamily,
        stringstyle=\color{red}\ttfamily,
        commentstyle=\color{green!70!black}\ttfamily,
    ]
jdoubleArray jniVectorConversion(JNIEnv* env, jobject, jdoubleArray arr) {
    jdouble* elements = (jdouble*)(*env).GetPrimitiveArrayCritical(arr, 0);
    (*env).ReleasePrimitiveArrayCritical(arr, elements, 0);
    return arr;
}
\end{lstlisting}
\caption{Get and release elements}
\label{fig:jni:conversion}
\end{figure}

The fourth and final test evaluated the performance of passing three arrays through \gls{jni} as well as the cost of getting and releasing the arrays. This test was included because the Columbia algorithm requires the precomputed trigonometric tables. This test is presented in Figure~\ref{fig:jni:columbia}.

\begin{figure}[H]
\begin{lstlisting}[
        language={C++},
        basicstyle=\ttfamily\footnotesize,
        keywordstyle=\color{blue}\ttfamily,
        stringstyle=\color{red}\ttfamily,
        commentstyle=\color{green!70!black}\ttfamily,
    ]
jdoubleArray jniColumbia(JNIEnv* env,
                         jobject obj,
                         jdoubleArray arr,
                         jdoubleArray cos,
                         jdoubleArray sin) {
    jdouble* elements = (jdouble*)(*env).GetPrimitiveArrayCritical(arr, 0);
    jdouble* sin_v    = (jdouble*)(*env).GetPrimitiveArrayCritical(sin, 0);
    jdouble* cos_v    = (jdouble*)(*env).GetPrimitiveArrayCritical(cos, 0);
    (*env).ReleasePrimitiveArrayCritical(arr, elements, 0);
    (*env).ReleasePrimitiveArrayCritical(sin, sin_v, 0);
    (*env).ReleasePrimitiveArrayCritical(cos, cos_v, 0);
    return arr;
}
\end{lstlisting}
\caption{JNI overhead for Columbia FFT}
\label{fig:jni:columbia}
\end{figure}

\section{Fast Fourier Transform Algorithms}
Different implementations of \gls{fft} were used in the libraries test. Three of them were implemented in Java and one in C. The implementations chosen were all contained in one file. The following algorithms were used to compare and find a good estimate on the performance of \gls{fft} implementations with varying complexity:

\begin{itemize}
    \item Princeton Recursive \cite{princeton:recursive}
    \item Princeton Iterative \cite{princeton:iterative}
    \item Columbia Iterative \cite{columbia:iterative}
    \item Kiss (\emph{Keep It Simple, Stupid}) \gls{fft} \cite{kiss:fft}
\end{itemize}

\subsection{Java Libraries}

The Princeton Recursive \gls{fft} is a straightforward implementation of the \gls{fft} with no radical optimizations. It was implemented in Java by Robert Sedgewick and Kevin Wayne \cite{princeton:recursive}. Twiddle factors are trigonometric constants used during the butterfly operations. They are not precomputed in this algorithm, leading to duplicate work when calling it multiple times.

Princeton Iterative, also written by Robert Sedgewick and Kevin Wayne \cite{princeton:iterative}, is an iterative version of the previous \gls{fft} (also written in Java). Iterative bit reversal and butterfly operations are used to produce a faster algorithm.

Columbia Iterative \cite{columbia:iterative} uses pre-computed trigonometric tables that are prepared in the class constructor. Because you commonly call \gls{fft} for the same sizes in your program, it is beneficial to have the trigonometric tables saved and use them in subsequent calls to the \gls{fft}.

\subsection{C++ Libraries}
Conversion to C++ was done manually for Princeton Iterative, Princeton Recursive and Columbia Iterative. Some changes were necessary to follow the C++ syntax. The Complex class used in Java was replaced by \texttt{std::complex} in all converted programs. Java dynamic arrays were replaced by \texttt{std::vector} for when they were created. This only occurred in the Princeton Recursive algorithm. In Princeton Iterative and Columbia Iterative, a Java array reference was sent to the function and there were no arrays created in the functions. In C++, a pointer and a variable containing the array size was used instead.

Kiss \gls{fft} is a small library written in C that consists of one source file. It is available under the BSD license. To use it, you first call the \texttt{kiss\_fft\_alloc} function which allocates memory for the twiddle factors as well as calculates them. This function returns a struct object that is used as a config. The \gls{fft} is executed when the \texttt{kiss\_fft} function is called. The first parameter for this function is the config returned by the init function, followed by a pointer to the time domain input and a pointer to where the frequency output will be placed.

\section{NEON Optimization}
% => http://edp.org/work/Construction.pdf <== OPTIMIZATION
% https://aaltodoc.aalto.fi/bitstream/handle/123456789/23201/master_Sugawara_Koki_2016.pdf?sequence=1

Two libraries were chosen to test how vectorization of the loops can improve performance. Both libraries were written in Intel SSE intrinsics and were converted to ARM NEON intrinsics. \texttt{float} was used so that the vector registers could hold 4 elements. It is possible to have the register hold two double precision variables although this would increase the number of instructions needed to calculate the \gls{fft}. For memory locality, this is also inefficient.

The first \gls{fft} algorithm was a recursive implementation written by Anthony Blake~\cite{neon:recursive}. This algorithm has an initializer function that allocates space for the twiddle factors and calculates them. They are placed in a two dimensional array that utilizes memory locality to waste less memory bandwidth \cite{neon:recursive:details}. The converted program is located in the project repo with the following link\footnote{\url{https://github.com/anddani/thesis/blob/master/BenchmarkApp/app/src/main/cpp/FFTRecursiveNeon.cpp}}. The second algorithm was an iterative implementation. This library is a straightforward implementation of \gls{fft} with SSE \cite{code:manyears} and was written for a sound source localization system \cite{manyears:site}. The code that was converted from SSE to NEON is located at this URL\footnote{\url{https://github.com/anddani/thesis/blob/master/BenchmarkApp/app/src/main/cpp/FFTIterativeNeon.cpp}}.
